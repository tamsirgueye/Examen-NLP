{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "affbbd42",
   "metadata": {},
   "source": [
    "<h1>I. Question de cours</h1>\n",
    "\n",
    "<h2>a. Définition et importance du NLP</h2>\n",
    "\n",
    "Le NLP (Traitement Automatique du Langage Naturel) est un domaine de l'informatique et de l'intelligence artificielle qui se concentre sur la manière dont les ordinateurs interagissent avec le langage humain. Il vise à permettre aux machines de comprendre, d'analyser et de générer du texte ou de la parole de manière similaire à la façon dont les humains le font.<br>\n",
    "Le NLP est important dans l'informatique car il permet aux ordinateurs de traiter et d'interpréter un langage humain, ce qui ouvre la porte à de nombreuses applications pratiques, telles que la traduction automatique, la recherche d'informations, l'analyse de sentiments, la génération de texte, la résumé automatique, etc.\n",
    "\n",
    "<h2>b. Les principales étapes du traitement du langage naturel</h2>\n",
    "\n",
    "Les principales étapes du traitement du langage naturel sont les suivantes :\n",
    "\n",
    "<ul><li>Prétraitement : Cette étape consiste à nettoyer et préparer les données textuelles en supprimant la ponctuation, les mots inutiles, en mettant en minuscules, etc.</li>\n",
    "<li>Tokenisation : Le texte est divisé en unités de sens, appelées \"tokens\", qui sont généralement des mots ou des phrases.</li>\n",
    "<li>Analyse syntaxique : Cela implique l'analyse de la structure grammaticale du texte pour comprendre les relations entre les mots et les phrases.</li>\n",
    "<li>Analyse sémantique : Elle vise à comprendre le sens du texte en associant les mots à des concepts et en identifiant les entités nommées.</li>\n",
    "<li>Traitement des informations : Cette étape consiste à extraire des informations pertinentes du texte, comme des entités, des relations ou des concepts clés.</li>\n",
    "<li>Modélisation du langage : Les modèles de langage sont utilisés pour prédire la probabilité des mots suivants dans une séquence de texte, ce qui est essentiel pour la génération de texte.</li></ul>\n",
    "\n",
    "<h2>c. Les principales applications du NLP dans le monde réel</h2>\n",
    "\n",
    "Les principales applications du NLP dans le monde réel incluent :\n",
    "\n",
    "<ul><li>Traduction automatique, par exemple, Google Translate.</li>\n",
    "    <li>Analyse de sentiment pour évaluer les opinions des utilisateurs sur les médias sociaux.</li>\n",
    "    <li>Résumé automatique pour créer des résumés concis de textes longs.</li>\n",
    "    <li>Chatbots et assistants virtuels pour fournir des réponses aux questions des utilisateurs.</li>\n",
    "<li>Extraction d'informations à partir de textes volumineux, tels que l'extraction de données médicales à partir de dossiers de patients.</li>\n",
    "    <li>Analyse de texte juridique pour la recherche de précédents juridiques.</li>\n",
    "    <li>Correction orthographique et grammaticale dans les outils de traitement de texte.</li></ul>\n",
    "\n",
    "<h2>d. Défis courants auxquels les modèles de NLP sont confrontés</h2>\n",
    "\n",
    "Les défis courants auxquels les modèles de NLP sont confrontés incluent :\n",
    "\n",
    "<ul><li>Biais : Les modèles de NLP peuvent contenir des biais provenant des données d'entraînement, ce qui peut conduire à des résultats discriminatoires ou inéquitables.</li>\n",
    "<li>Généralisation : Les modèles de NLP peuvent ne pas généraliser correctement à de nouveaux contextes ou domaines.</li>\n",
    "<li>Compréhension contextuelle : La compréhension du contexte et de l'ironie dans le langage naturel reste un défi.</li>\n",
    "<li>Traitement de langues moins courantes : Les modèles de NLP sont souvent plus performants pour les langues courantes et moins pour les langues moins répandues.</li>\n",
    "<li>Besoin de données massives : Les modèles de NLP nécessitent de grandes quantités de données pour l'entraînement, ce qui peut être coûteux et problématique en matière de confidentialité.</li></ul>\n",
    "\n",
    "<h2>e. Evaluation de la performance d'un modèle de NLP</h2>\n",
    "\n",
    "La performance d'un modèle de NLP est évaluée à l'aide de différentes métriques, notamment :\n",
    "\n",
    "<ul><li>Précision : Mesure la proportion de prédictions correctes du modèle.</li>\n",
    "    <li>Rappel : Mesure la proportion d'exemples positifs correctement identifiés.</li>\n",
    "<li>F1-score : Une métrique qui combine la précision et le rappel pour évaluer la performance globale du modèle.</li>\n",
    "    <li>Score BLEU : Utilisé pour évaluer la qualité des traductions automatiques.</li>\n",
    "<li>Perplexité : Mesure la capacité d'un modèle de langage à prédire correctement des séquences de mots.</li>\n",
    "    <li>ROUGE : Utilisé pour évaluer la qualité des résumés automatiques.</li>\n",
    "<li>Score d'exactitude pour les chatbots : Évalue la précision des réponses générées par le modèle lors des conversations.</li></ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f173f90b",
   "metadata": {},
   "source": [
    "<h1>II. Modélisation</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a2c5d76",
   "metadata": {},
   "source": [
    "<h2>1. Téléchargement des données</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "04e30def",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b4a1e8e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('Restaurant_Reviews.tsv', delimiter='\\t',quoting = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "45181e5f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>Liked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>I think food should have flavor and texture an...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>Appetite instantly gone.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>Overall I was not impressed and would not go b...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>The whole experience was underwhelming, and I ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>Then, as if I hadn't wasted enough of my life ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Review  Liked\n",
       "995  I think food should have flavor and texture an...      0\n",
       "996                           Appetite instantly gone.      0\n",
       "997  Overall I was not impressed and would not go b...      0\n",
       "998  The whole experience was underwhelming, and I ...      0\n",
       "999  Then, as if I hadn't wasted enough of my life ...      0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aee0c802",
   "metadata": {},
   "source": [
    "<h2>2. Prétraitement des données</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3f786681",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\gueye\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "\n",
    "corpus = []\n",
    "\n",
    "for i in range(0, 1000):\n",
    "    review = re.sub('[^a-zA-Z]', ' ', dataset['Review'][i])\n",
    "    review = review.lower()\n",
    "    review = review.split()\n",
    "    ps = PorterStemmer()\n",
    "    review = [ps.stem(word) for word in review if not word in set(stopwords.words('english'))]\n",
    "    review = ' '.join(review)\n",
    "    corpus.append(review)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78da373c",
   "metadata": {},
   "source": [
    "<div style=\"font-size: 1.2em\">Le prétraitement des données est une étape essentielle dans le traitement du texte avant de les utiliser pour l'apprentissage automatique ou l'analyse. Il aide à nettoyer, organiser et préparer les données textuelles de manière à les rendre adaptées à l'analyse. Voici les étapes de prétraitement que nous avons effectuées dans notre code :</div>\n",
    "\n",
    "<h3>Suppression des caractères non alphabétiques et numériques :</h3>\n",
    "\n",
    "<code>review = re.sub('[^a-zA-Z]', ' ', dataset['Review'][i])</code><br>\n",
    "Importance : Cela élimine tous les caractères spéciaux, la ponctuation et les chiffres, ne conservant que les lettres. Cela simplifie le texte et permet de se concentrer sur le contenu textuel réel.\n",
    "\n",
    "<h3>Mise en minuscule :</h3>\n",
    "\n",
    "<code>review = review.lower()</code><br>\n",
    "Importance : La mise en minuscule garantit que les mots écrits en majuscules et en minuscules sont traités de la même manière, réduisant ainsi la complexité du modèle.\n",
    "\n",
    "<h3>Tokenization (découpage en mots) :</h3>\n",
    "\n",
    "<code>review = review.split()</code><br>\n",
    "Importance : Diviser le texte en mots individuels facilite l'analyse et la comptabilisation des mots uniques.\n",
    "\n",
    "<h3>Stemming (réduction des mots à leur racine) :</h3>\n",
    "\n",
    "<code>ps = PorterStemmer(); review = [ps.stem(word) for word in review if not word in set(stopwords.words('english'))]</code><br>\n",
    "Importance : Le stemming réduit les mots à leur forme de base, ce qui réduit la dimensionnalité des données en combinant des mots similaires. Par exemple, \"loved,\" \"loving,\" et \"will love\" sont réduits à \"love.\"\n",
    "\n",
    "<h3>Suppression des stopwords :</h3>\n",
    "\n",
    "<code>review = [ps.stem(word) for word in review if not word in set(stopwords.words('english'))]</code><br>\n",
    "Importance : Les stopwords sont des mots courants tels que \"the,\" \"and,\" \"of,\" qui ne portent pas de sens distinctif et peuvent être supprimés pour réduire le bruit dans les données.\n",
    "\n",
    "<h3>Reconstitution du texte :</h3>\n",
    "\n",
    "<code>review = ' '.join(review)</code><br>\n",
    "Importance : Réassembler les mots après le nettoyage pour former une représentation de texte prête à être utilisée dans le modèle."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "954862a1",
   "metadata": {},
   "source": [
    "<h2>3. Le modèle Naïve Bayes gaussien</h2>\n",
    "Le modèle de classification de texte basé sur le classificateur Naïve Bayes gaussien est un modèle relativement simple et interprétable. Voici sa structure, son architecture et son fonctionnement :\n",
    "\n",
    "<h3>a. Structure du modèle :</h3>\n",
    "Le modèle de classification de texte basé sur le classificateur Naïve Bayes gaussien repose sur le théorème de Bayes et repose sur l'hypothèse d'indépendance conditionnelle des caractéristiques (d'où le terme \"Naïve\"). Il est utilisé pour attribuer des classes aux textes en se basant sur des caractéristiques extraites des données textuelles.\n",
    "\n",
    "<h3>b. Architecture du modèle :</h3>\n",
    "L'architecture du modèle est relativement simple et consiste en :\n",
    "\n",
    "<strong>Extraction des caractéristiques (Bag of Words) :</strong><br>\n",
    "Le modèle commence par représenter chaque document texte comme un ensemble de caractéristiques (mots ou n-grammes) et leurs fréquences d'apparition dans le texte. Cette représentation est appelée \"Bag of Words\" (BoW).\n",
    "\n",
    "<strong>Calcul des probabilités de classe :</strong><br>\n",
    "Le modèle calcule la probabilité qu'un texte donné appartienne à chaque classe possible. Cela se fait en utilisant le théorème de Bayes pour estimer la probabilité a posteriori de chaque classe étant donné le texte.\n",
    "\n",
    "<strong>Prédiction de classe :</strong><br>\n",
    "Le modèle attribue le texte à la classe avec la probabilité la plus élevée.\n",
    "\n",
    "<h3>c. Fonctionnement du modèle :</h3>\n",
    "\n",
    "<strong>Extraction des caractéristiques (Bag of Words) :</strong><br>\n",
    "Les caractéristiques (mots ou n-grammes) sont extraites à partir du texte en créant un vocabulaire de toutes les caractéristiques uniques dans le corpus. La fréquence d'apparition de chaque caractéristique dans le texte est enregistrée.\n",
    "\n",
    "<strong>Entraînement du modèle :</strong><br>\n",
    "Pendant la phase d'entraînement, le modèle calcule les statistiques (moyenne et variance) des caractéristiques pour chaque classe. Ces statistiques servent à estimer les probabilités a priori et les probabilités conditionnelles nécessaires pour le calcul des probabilités de classe.\n",
    "\n",
    "<strong>Classification des nouveaux textes :</strong><br>\n",
    "Lorsqu'un nouveau texte doit être classifié, le modèle calcule les probabilités conditionnelles pour chaque classe en utilisant les statistiques d'entraînement. Ensuite, il applique le théorème de Bayes pour calculer la probabilité a posteriori de chaque classe étant donné le texte.\n",
    "\n",
    "<strong>Prédiction de classe :</strong><br>\n",
    "Le modèle attribue le texte à la classe avec la probabilité a posteriori la plus élevée. En d'autres termes, il choisit la classe pour laquelle la probabilité conditionnelle est maximale.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57b7dee2",
   "metadata": {},
   "source": [
    "<h2>4. Entrainement du modèle</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "81cfb9a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "cv = CountVectorizer(max_features = 1500)\n",
    "X = cv.fit_transform(corpus).toarray()\n",
    "y = dataset.iloc[:, 1].values\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20, random_state = 0)\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "classifier = GaussianNB()\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "y_pred = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84c1ae31",
   "metadata": {},
   "source": [
    "<h2>5. Evaluation du modèle</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aa8329be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrice de confusion :\n",
      "[[55 42]\n",
      " [12 91]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Calcul de la matrice de confusion\n",
    "confusion = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "print('Matrice de confusion :')\n",
    "print(confusion)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63a133f5",
   "metadata": {},
   "source": [
    "La matrice de confusion est souvent utilisée pour analyser les performances d'un modèle de classification binaire. Dans ce contexte, chaque entrée de la matrice représente le nombre d'échantillons dans une catégorie spécifique.\n",
    "\n",
    "La première rangée concerne la classe réelle \"négatif\".\n",
    "\n",
    "La deuxième rangée concerne la classe réelle \"positif\".\n",
    "\n",
    "La première colonne concerne les prédictions du modèle comme \"négatif\".\n",
    "\n",
    "La deuxième colonne concerne les prédictions du modèle comme \"positif\".\n",
    "\n",
    "<strong>Interprétation de la matrice de confusion :</strong><br>\n",
    "\n",
    "Vrais positifs (True Positives, TP) : Il y a 91 échantillons qui sont réellement de la classe \"positif\" (deuxième rangée) et que le modèle a correctement prédits comme \"positif\" (deuxième colonne).\n",
    "\n",
    "Vrais négatifs (True Negatives, TN) : Il y a 55 échantillons qui sont réellement de la classe \"négatif\" (première rangée) et que le modèle a correctement prédits comme \"négatif\" (première colonne).\n",
    "\n",
    "Faux positifs (False Positives, FP) : Il y a 42 échantillons qui sont réellement de la classe \"négatif\" (première rangée) mais que le modèle a incorrectement prédits comme \"positif\" (deuxième colonne). C'est une erreur de type I.\n",
    "\n",
    "Faux négatifs (False Negatives, FN) : Il y a 12 échantillons qui sont réellement de la classe \"positif\" (deuxième rangée) mais que le modèle a incorrectement prédits comme \"négatif\" (première colonne). C'est une erreur de type II."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43c967d4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
